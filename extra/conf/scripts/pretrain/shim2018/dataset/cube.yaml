dataset_artifact_name: "cube/cube_split_1"
batch_size: 128 # shim2018 paper
epochs: 10
limit_train_batches: null
limit_val_batches: null

lr: 1e-3
min_masking_probability: 0.0
max_masking_probability: 0.9
encoder:
  output_size: 16 # shim2018 paper
  reading_block_cells: [32, 32] # shim2018 paper
  writing_block_cells: [32, 32] # not specified by shim2018 paper, assume it is the same as reading_block_cells
  memory_size: 16 # shim2018 paper
  processing_steps: 5 # original set encoding paper
  dropout: 0.0
classifier:
  num_cells: [32, 32] # shim2018 paper (cube dataset)
