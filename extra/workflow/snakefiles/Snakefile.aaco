configfile: "extra/workflow/conf/aaco_soft_budget.yaml"

# Define global variables from config values
EXPERIMENT_ID = config["experiment_id"]
DATASET_ARTIFACT_ALIASES = config["dataset_artifact_aliases"]
EVAL_BATCH_SIZE_PER_DATASET = config.get("batch_size_per_dataset", {})
DATASET_SPLITS = config["dataset_splits"]
DATASET_SPLIT_MODE = config["dataset_split_mode"]
CLASSIFIER = config["classifier"]
CLASSIFIER_ARTIFACT_ALIASES = config["classifier_artifact_aliases"]
VALIDATE_ARTIFACTS = config["validate_artifacts"]
SEEDS = config["seeds"]
TRAIN_DEVICE = config["train_device"]
EVAL_DEVICE = config["eval_device"]
COST_PARAMS_PER_METHOD = config["cost_params_per_method"]
SMOKE_TEST = config["smoke_test"]

METHODS = ["aaco"]  # Only AACO in this file
DATASETS = list(DATASET_ARTIFACT_ALIASES.keys())

def get_cost_params(dataset: str):
    """Get cost parameters for AACO on a specific dataset."""
    if dataset in COST_PARAMS_PER_METHOD["aaco"]:
        return COST_PARAMS_PER_METHOD["aaco"][dataset]
    else:
        return COST_PARAMS_PER_METHOD["aaco"].get("default", [0.05])

def get_batch_size(dataset: str):
    """Get batch size for a specific dataset."""
    return EVAL_BATCH_SIZE_PER_DATASET.get(dataset, 128)

# Main rule to run complete soft budget pipeline
rule soft_budget:
    input:
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/eval/combined.csv",
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/plot1.pdf",
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/plot2.pdf",
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/plot3.pdf",

rule soft_budget_train_all:
    input:
        [
            f"extra/experiments/{EXPERIMENT_ID}/indicators/soft_budget/trained_method/aaco/{dataset}/split{dataset_split}/costparam{cost_param}/seed{seed}.done"
            for dataset in DATASETS
            for dataset_split in DATASET_SPLITS
            for cost_param in get_cost_params(dataset)
            for seed in SEEDS
        ],

rule soft_budget_eval_all:
    input:
        [
            f"extra/experiments/{EXPERIMENT_ID}/indicators/soft_budget/eval/aaco/{dataset}/split{dataset_split}/costparam{cost_param}/seed{seed}.done"
            for dataset in DATASETS
            for dataset_split in DATASET_SPLITS
            for cost_param in get_cost_params(dataset)
            for seed in SEEDS
        ],

# Training rule for AACO (no pretraining needed)
rule train_soft_budget_aaco:
    output:
        touch(
            f"extra/experiments/{EXPERIMENT_ID}/indicators/soft_budget/trained_method/aaco/{{dataset}}/split{{dataset_split}}/costparam{{cost_param}}/seed{{seed}}.done"
        ),
    params:
        dataset_specific_args=lambda wildcards: (
            f"dataset@_global_={wildcards.dataset}_smoke"
            if SMOKE_TEST
            else f"dataset@_global_={wildcards.dataset}"
        ),
        dataset_artifact_name=lambda wildcards: f"{wildcards.dataset}_split_{wildcards.dataset_split}:{DATASET_ARTIFACT_ALIASES[wildcards.dataset]}",
    shell:
        """
        WANDB_HTTP_TIMEOUT=60 uv run scripts/train_methods/train_aaco.py \
            {params.dataset_specific_args} \
            dataset_artifact_name={params.dataset_artifact_name} \
            seed={wildcards.seed} \
            cost_param={wildcards.cost_param} \
            output_artifact_aliases=["{EXPERIMENT_ID}"] \
            device={TRAIN_DEVICE}
        """

# Evaluation rule for AACO
rule eval_soft_budget_aaco:
    input:
        f"extra/experiments/{EXPERIMENT_ID}/indicators/soft_budget/trained_method/aaco/{{dataset}}/split{{dataset_split}}/costparam{{cost_param}}/seed{{seed}}.done",
    output:
        touch(
            f"extra/experiments/{EXPERIMENT_ID}/indicators/soft_budget/eval/aaco/{{dataset}}/split{{dataset_split}}/costparam{{cost_param}}/seed{{seed}}.done"
        ),
    params:
        classifier_arg=lambda wildcards: f"trained_classifier_artifact_name={CLASSIFIER}-{wildcards.dataset}_split_{wildcards.dataset_split}:{CLASSIFIER_ARTIFACT_ALIASES[wildcards.dataset]}",
        batch_size=lambda wildcards: get_batch_size(wildcards.dataset),
        trained_method_artifact_name=lambda wildcards: f"train_aaco-{wildcards.dataset}_split_{wildcards.dataset_split}-costparam_{wildcards.cost_param}-seed_{wildcards.seed}:{EXPERIMENT_ID}",
    shell:
        """
        WANDB_HTTP_TIMEOUT=60 uv run scripts/evaluation/eval_soft_afa_method.py \
            trained_method_artifact_name={params.trained_method_artifact_name} \
            cost_param={wildcards.cost_param} \
            {params.classifier_arg} \
            output_artifact_aliases=["{EXPERIMENT_ID}"] \
            seed=null \
            device={EVAL_DEVICE} \
            eval_only_n_samples=null \
            dataset_split={DATASET_SPLIT_MODE} \
            validate_artifacts={VALIDATE_ARTIFACTS} \
            batch_size={params.batch_size}
        """

# Download evaluation results
rule download_soft_budget_eval_result:
    input:
        f"extra/experiments/{EXPERIMENT_ID}/indicators/soft_budget/eval/aaco/{{dataset}}/split{{dataset_split}}/costparam{{cost_param}}/seed{{seed}}.done",
    output:
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/eval/aaco/{{dataset}}/split{{dataset_split}}/costparam{{cost_param}}/seed{{seed}}/soft_eval_data.csv",
    params:
        experiment_id=EXPERIMENT_ID,
    shell:
        """
        WANDB_HTTP_TIMEOUT=60 uv run wandb artifact get \
            train_aaco-{wildcards.dataset}_split_{wildcards.dataset_split}-costparam_{wildcards.cost_param}-seed_{wildcards.seed}-{CLASSIFIER}-{wildcards.dataset}_split_{wildcards.dataset_split}:{EXPERIMENT_ID} \
            --root experiments/{params.experiment_id}/results/soft_budget/eval/aaco/{wildcards.dataset}/split{wildcards.dataset_split}/costparam{wildcards.cost_param}/seed{wildcards.seed}
        """

# Add dataset split column to results
rule add_dataset_split_col_to_soft_budget_eval_result:
    input:
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/eval/aaco/{{dataset}}/split{{dataset_split}}/costparam{{cost_param}}/seed{{seed}}/soft_eval_data.csv",
    output:
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/eval/aaco/{{dataset}}/split{{dataset_split}}/costparam{{cost_param}}/seed{{seed}}/soft_eval_data_with_split.csv",
    conda:
        "../envs/R.yaml"
    shell:
        """
        Rscript scripts/misc/add_dataset_split_col.R {input} {output} {wildcards.dataset_split}
        """

# Combine all evaluation results
rule combine_soft_budget_eval_results:
    input:
        [
            f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/eval/aaco/{dataset}/split{dataset_split}/costparam{cost_param}/seed{seed}/soft_eval_data_with_split.csv"
            for dataset in DATASETS
            for dataset_split in DATASET_SPLITS
            for cost_param in get_cost_params(dataset)
            for seed in SEEDS
        ],
    output:
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/eval/combined.csv",
    conda:
        "../envs/R.yaml"
    shell:
        """
        Rscript scripts/misc/combine_soft_budget_results.R {input} {output}
        """

# Generate plots from combined results
rule soft_budget_plot:
    input:
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/eval/combined.csv",
    output:
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/plot1.pdf",
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/plot2.pdf",
        f"extra/experiments/{EXPERIMENT_ID}/results/soft_budget/plot3.pdf",
    conda:
        "../envs/R.yaml"
    shell:
        """
        Rscript scripts/plotting/produce_soft_budget_plots.R {input} {output}
        """
