DATASETS = ["cube", "AFAContext"]
DATASET_INSTANCE_INDICES = [0, 1]
INITIALIZER = "cold"
UNMASKER_PER_DATASET = {"cube": "tabular_direct", "AFAContext": "tabular_direct"}
DATASET_SPLIT = "val"

# Main parameters that we investigate
# - hard budget during training
# - hard budget during evaluation
# - soft budget parameter during training
# - soft budget parameter during evaluation
PARAMS_PER_DATASET = {
    "cube": [
        (5, 5, None, None),
        (10, 10, None, None),
        (None, None, 0.4, None),
        (None, None, 0.6, None),
    ],
    "AFAContext": [
        (10, 10, None, None),
        (15, 15, None, None),
        (None, None, 0.5, None),
        (None, None, 0.7, None),
    ],
}


rule all:
    input:
        "extra/plot_results/random_dummy",


rule train_method:
    input:
        "extra/data/datasets/{dataset}/{dataset_instance_idx}",
    output:
        directory(
            "extra/trained_methods/random_dummy/dataset-{dataset}+instance_idx-{dataset_instance_idx}/train_hard_budget-{train_hard_budget}+train_soft_budget_param-{train_soft_budget_param}"
        ),
    params:
        unmasker=lambda wildcards: UNMASKER_PER_DATASET[wildcards.dataset],
    shell:
        """
        python scripts/train/randomdummy.py \
            dataset_artifact_path={input} \
            save_path={output} \
            initializer_type={INITIALIZER} \
            unmasker_type={params.unmasker} \
            train_hard_budget={wildcards.train_hard_budget} \
            train_soft_budget_param={wildcards.train_soft_budget_param}
        """


# rule train_classifier:
#     input:
#         "extra/data/datasets/{dataset}/{dataset_instance_idx}",
#     output:
#         directory(
#             "extra/trained_classifiers/masked_mlp_classifier/dataset-{dataset}+instance_idx-{dataset_instance_idx}"
#         ),
#     shell:
#         """
#         python scripts/train/masked_mlp_classifier.py \
#             dataset_artifact_path={input} \
#         """


rule eval_method:
    input:
        "extra/data/datasets/{dataset}/{dataset_instance_idx}",
        "extra/trained_methods/random_dummy/dataset-{dataset}+instance_idx-{dataset_instance_idx}/train_hard_budget-{train_hard_budget}+train_soft_budget_param-{train_soft_budget_param}",
        # "extra/trained_classifiers/masked_mlp_classifier/dataset-{dataset}+instance-{dataset_instance}",
    output:
        "extra/eval_results/random_dummy/dataset-{dataset}+instance_idx-{dataset_instance_idx}/train_hard_budget-{train_hard_budget}+train_soft_budget_param-{train_soft_budget_param}/eval_hard_budget+{eval_hard_budget}+eval_soft_budget_param-{eval_soft_budget_param}.csv",
    params:
        unmasker=lambda wildcards: UNMASKER_PER_DATASET[wildcards.dataset],
    shell:
        """
        python scripts/eval/eval_afa_method.py \
            method_artifact_path={input[1]} \
            unmasker_type={params.unmasker} \
            initializer_type={INITIALIZER} \
            dataset_artifact_path={input[0]} \
            save_path={output} \
            dataset_split={DATASET_SPLIT} \
            classifier_artifact_path=null \
            device={DEVICE} \
            n_selection_choices={} \
            hard_budget={wildcards.train_hard_budget} \
        """


rule merge_eval:
    input:
        [
            f"extra/eval_results/random_dummy/dataset-{dataset}+instance_idx-{dataset_instance_idx}/train_hard_budget-{train_hard_budget}+train_soft_budget_param-{train_soft_budget_param}/eval_hard_budget+{eval_hard_budget}+eval_soft_budget_param-{eval_soft_budget_param}.csv"
            for dataset in DATASETS
            for dataset_instance_idx in DATASET_INSTANCE_INDICES
            for (
                train_hard_budget,
                eval_hard_budget,
                train_soft_budget_param,
                eval_soft_budget_param,
            ) in PARAMS_PER_DATASET[dataset]
        ],
    output:
        "extra/merged_eval_results/random_dummy.csv",
    shell:
        """
            csvstack {input} > {output}
        """


rule plot:
    input:
        "extra/merged_eval_results/random_dummy.csv",
    output:
        directory("extra/plot_results/random_dummy"),
    shell:
        """
            Rscript scripts/plotting/plot_eval.py {output}
        """
