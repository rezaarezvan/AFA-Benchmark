DATASET_INSTANCE_INDICES = [0, 1]
INITIALIZER = "cold"  # assume same initializer for now
UNMASKER_PER_DATASET = {
    "cube": "direct",
    "afa_context": "direct",
    "synthetic_mnist": "28x28_to_4x4",
}
EVAL_DATASET_SPLIT = "val"  # whether to use "val" or "test" during evaluation
DEVICE = "cpu"
USE_WANDB = False
SMOKE_TEST = True

# Main parameters that we investigate
# - hard budget
# - soft budget parameter during training
PARAMS_PER_METHOD_AND_DATASET = {
    "shim2018": {
        "cube": [
            (5, "null"),
            (10, "null"),
            ("null", 0.4),
            ("null", 0.6),
        ],
        "afa_context": [
            (10, "null"),
            (15, "null"),
            ("null", 0.5),
            ("null", 0.7),
        ],
        "synthetic_mnist": [
            (4, "null"),
            (10, "null"),
            ("null", 0.2),
            ("null", 0.3),
        ],
    },
}
DATASETS = UNMASKER_PER_DATASET.keys()
METHODS = PARAMS_PER_METHOD_AND_DATASET.keys()


rule all:
    input:
        "extra/plot_results/RL",

rule pretrain_model:
    input:
        "extra/data/datasets/{dataset}/{dataset_instance_idx}/train.bundle",
        "extra/data/datasets/{dataset}/{dataset_instance_idx}/val.bundle",
    output:
        directory(
            "extra/pretrained_models/{method}/"
                "dataset-{dataset}+"
                "instance_idx-{dataset_instance_idx}/"
                    "pretrain_seed-{pretrain_seed}.bundle"
        ),
    params:
        smoke_test_args="" if not SMOKE_TEST else "limit_train_batches=1 limit_val_batches=1 epochs=1 ",
    shell:
        """
        python scripts/pretrain/{wildcards.method}.py \
            train_dataset_bundle_path={input[0]} \
            val_dataset_bundle_path={input[1]} \
            save_path={output} \
            device={DEVICE} \
            seed={wildcards.pretrain_seed} \
            use_wandb={USE_WANDB} \
            +experiment@_global_={wildcards.dataset} \
            {params.smoke_test_args}
        """

rule train_method:
    input:
        "extra/data/datasets/{dataset}/{dataset_instance_idx}/train.bundle",
        "extra/data/datasets/{dataset}/{dataset_instance_idx}/val.bundle",

        "extra/pretrained_models/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}.bundle"
    output:
        directory(
            "extra/trained_methods/{method}/"
                "dataset-{dataset}+"
                "instance_idx-{dataset_instance_idx}/"
                    "pretrain_seed-{pretrain_seed}/"
                        "train_seed-{train_seed}+"
                        "train_hard_budget-{train_hard_budget}+"
                        "train_soft_budget_param-{train_soft_budget_param}.bundle"
        ),
    params:
        unmasker=lambda wildcards: UNMASKER_PER_DATASET[wildcards.dataset],
        smoke_test_args="" if not SMOKE_TEST else "n_batches=2",
    shell:
        """
        python scripts/train/{wildcards.method}.py \
            train_dataset_bundle_path={input[0]} \
            val_dataset_bundle_path={input[1]} \
            pretrained_model_bundle_path={input[2]} \
            save_path={output} \
            components/initializers@initializer={INITIALIZER} \
            components/unmaskers@unmasker={params.unmasker} \
            hard_budget={wildcards.train_hard_budget} \
            soft_budget_param={wildcards.train_soft_budget_param} \
            device={DEVICE} \
            seed={wildcards.train_seed} \
            use_wandb={USE_WANDB} \
            +experiment@_global_={wildcards.dataset} \
            {params.smoke_test_args}
        """


# rule train_classifier:
#     input:
#         "extra/data/datasets/{dataset}/{dataset_instance_idx}",
#     output:
#         directory(
#             "extra/trained_classifiers/masked_mlp_classifier/dataset-{dataset}+instance_idx-{dataset_instance_idx}"
#         ),
#     shell:
#         """
#         python scripts/train/masked_mlp_classifier.py \
#             dataset_artifact_path={input} \
#         """


rule eval_method:
    input:
        f"extra/data/datasets/{{dataset}}/{{dataset_instance_idx}}/{EVAL_DATASET_SPLIT}.bundle",

        "extra/trained_methods/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}.bundle",
        # "extra/trained_classifiers/masked_mlp_classifier/dataset-{dataset}+instance-{dataset_instance}",
    output:
        "extra/eval_results/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    params:
        unmasker=lambda wildcards: UNMASKER_PER_DATASET[wildcards.dataset],
        smoke_test_args="" if not SMOKE_TEST else "eval_only_n_samples=10 batch_size=2",
    shell:
        """
        python scripts/eval/eval_afa_method.py \
            method_bundle_path={input[1]} \
            components/initializers@initializer={INITIALIZER} \
            components/unmaskers@unmasker={params.unmasker} \
            dataset_bundle_path={input[0]} \
            save_path={output} \
            classifier_bundle_path=null \
            seed={wildcards.eval_seed} \
            device={DEVICE} \
            hard_budget={wildcards.eval_hard_budget} \
            use_wandb={USE_WANDB} \
            {params.smoke_test_args}
        """

# Add eval_soft_budget_param column. Not used by dummy methods, but kept for consistency.
rule add_eval_metadata_to_eval_data:
    input:
        "extra/eval_results/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    output:
        "extra/eval_results2/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    resources:
        shell_exec="nu"
    shell:
        """
        open {input} |
            insert eval_soft_budget_param "" |
                save {output}
        """

# Convert the `prev_selections_performed` (list[int]) and `selection_performed` columns into `selections_performed` (int)
rule count_selections:
    input:
        "extra/eval_results2/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    output:
        "extra/eval_results3/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    resources:
        shell_exec="nu"
    shell:
        """
        open {input} |
            insert selections_performed {{
                get prev_selections_performed | each {{ |row| ($row | from json | length) + 1}}
            }} |
            reject prev_selections_performed selection_performed |
                save {output}
        """

# Add some metadata columns from training
rule add_train_metadata_to_eval_data:
    input:
        "extra/eval_results3/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    output:
        "extra/eval_results4/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    resources:
        shell_exec="nu"
    shell:
        """
        open {input} |
            insert afa_method {wildcards.method} |
            insert dataset {wildcards.dataset} |
            insert train_seed {wildcards.train_seed} |
            insert train_hard_budget {wildcards.train_hard_budget} |
            insert train_soft_budget_param {wildcards.train_soft_budget_param} |
                save {output}
        """

# Make sure that train_hard_budget and eval_hard_budget are the same
# Rename this to hard_budget
# Make sure that only one of train_soft_budget_param and eval_soft_budget_param is set, if any
# Rename this to soft_budget_param
rule validate_hard_budget_and_soft_budget_param:
    input:
        "extra/eval_results4/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    output:
        "extra/eval_results5/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    resources:
        shell_exec="nu"
    shell:
        """
        use std/assert
        let df = open {input}
        let hard_budget_columns_are_same = $df |
            all {{|row| $row.train_hard_budget == $row.eval_hard_budget}}
        assert $hard_budget_columns_are_same
        let df = $df |
            rename --column {{ train_hard_budget: hard_budget }} |
            reject eval_hard_budget
        let not_both_soft_budget_param_non_null = $df |
            all {{|row|
                let train_is_null = ($row.train_soft_budget_param == "")
                let eval_is_null = ($row.eval_soft_budget_param == "")
                $train_is_null or $eval_is_null
            }}
        assert $not_both_soft_budget_param_non_null
        let df = $df |
            insert soft_budget_param {{|row|
                if $row.train_soft_budget_param != "" {{
                    $row.train_soft_budget_param
                }} else {{
                    $row.eval_soft_budget_param
                }}
            }} |
            reject train_soft_budget_param eval_soft_budget_param
        $df | save {output}
        """

# Instead of two separate classifier columns, the plotting script expects tidy data
rule pivot_long_classifier:
    input:
        "extra/eval_results5/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    output:
        "extra/eval_results6/{method}/"
            "dataset-{dataset}+"
            "instance_idx-{dataset_instance_idx}/"
                "pretrain_seed-{pretrain_seed}/"
                    "train_seed-{train_seed}+"
                    "train_hard_budget-{train_hard_budget}+"
                    "train_soft_budget_param-{train_soft_budget_param}/"
                        "eval_seed-{eval_seed}+"
                        "eval_hard_budget-{eval_hard_budget}/"
                            "eval_data.csv",
    resources:
        shell_exec="nu"
    shell:
        """
        open {input} |
            each {{ |row|
                [
                    ($row | insert classifier "builtin" | insert predicted_class $row.builtin_predicted_class),
                    ($row | insert classifier "external" | insert predicted_class $row.external_predicted_class)
                ]
            }} |
            flatten |
            reject builtin_predicted_class external_predicted_class |
                save {output}
        """

rule merge_eval:
    input:
        [
            (
                f"extra/eval_results6/{method}/"
                    f"dataset-{dataset}+"
                    f"instance_idx-{dataset_instance_idx}/"
                        f"pretrain_seed-{dataset_instance_idx}/"
                            f"train_seed-{dataset_instance_idx}+"
                            f"train_hard_budget-{hard_budget}+"
                            f"train_soft_budget_param-{soft_budget_param}/"
                                f"eval_seed-{dataset_instance_idx}+"
                                f"eval_hard_budget-{hard_budget}/"
                                    f"eval_data.csv"
            )
            for method in METHODS
            for dataset in DATASETS
            for dataset_instance_idx in DATASET_INSTANCE_INDICES
            for (
                hard_budget,
                soft_budget_param,
            ) in PARAMS_PER_METHOD_AND_DATASET[
                method
            ][dataset]
        ],
    output:
        "extra/merged_eval_results/RL.csv",
    shell:
        """
            csvstack {input} > {output}
        """


rule plot:
    input:
        "extra/merged_eval_results/RL.csv",
    output:
        directory("extra/plot_results/RL"),
    shell:
        """
            Rscript scripts/plotting/plot_eval.R {input} {output}
        """
